{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maen - Multiple agents ecosystem network\n",
    "\n",
    "There is a usage of Maen library in generatig a graph neural network to classify time series.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CDalgs, Maen\n",
    "using BSON, DataFrames\n",
    "using Graphs, SimpleWeightedGraphs\n",
    "using Flux, StatsBase, LinearAlgebra, IterTools, Random\n",
    "using Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_a = BSON.load(\"dataset_a.bson\")\n",
    "data_tensor = dataset_a[:data_tensor];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation graph on angents with features & clustering function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_clusters(smoothness, clustering)\n",
    "    clustering(correlation_graph(data_tensor; smoothness=smoothness))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate clustering methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncc95(g) = nc_clustering(g; α=.95)\n",
    "ncc99(g) = nc_clustering(g; α=.99)\n",
    "ncc999(g) = nc_clustering(g; α=.999)\n",
    "clustering_algs = [louvain_clustering, ncc95, ncc99, ncc999, cdep_clustering]\n",
    "\n",
    "smoothness = 0.8\n",
    "clustering_alg = clustering_algs[1]\n",
    "\n",
    "clusters = get_clusters(smoothness, clustering_alg);\n",
    "while length(unique(clusters)) != 6\n",
    "    clusters = get_clusters(smoothness, clustering_alg)\n",
    "end\n",
    "\n",
    "println(string(\"There are \", length(unique(clusters)), \" clusters.\\n\",\n",
    "    \"Create network with \", length(unique(clusters)), \" InputAgents and one OutputAgent. \n",
    "    The OutputAgent should return 4 scalars correspondign to the labes of material parameters.\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise results of clustering on all samples from the dataset (show distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = plot(xlabel=\"Deflection [m]\", ylabel=\"Loads [MN]\")\n",
    "for i=1:100\n",
    "    sample_i = data_tensor[i, :, :].*(-1)\n",
    "    last_point_idx = 1\n",
    "    for j in unique(clusters)\n",
    "        cmap_j_idxs = findall(x->x == j, clusters)\n",
    "        tmp = sample_i[union(cmap_j_idxs, last_point_idx), :]\n",
    "        last_point_idx = maximum(cmap_j_idxs)\n",
    "        scatter!(p, tmp[:, 1], tmp[:, 2], color= j!=0 ? palette(:tab20)[j] : :white, legend=false, markersize=2.5)\n",
    "    end\n",
    "    scatter!(p, \n",
    "        [sample_i[argmax(sample_i[:, 2]), :][1]], \n",
    "        [sample_i[argmax(sample_i[:, 2]), :][2]], color=:black, legend=false\n",
    "    )\n",
    "end\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise results of clustering on single particular sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function sample_plot(idx::Int64)\n",
    "    p = plot(xlabel=\"Deflection [m]\", ylabel=\"Loads [MN]\", xticks=(1, \"\"), yticks=(1, \"\"))\n",
    "    sample_i = data_tensor[idx, :, :].*(-1)\n",
    "    last_point_idx = 1\n",
    "    for j in unique(clusters)\n",
    "        cmap_j_idxs = findall(x->x == j, clusters)\n",
    "        tmp = sample_i[union(cmap_j_idxs, last_point_idx), :]\n",
    "        last_point_idx = maximum(cmap_j_idxs)\n",
    "        scatter!(p, tmp[:, 1], tmp[:, 2], color = j != 0 ? palette(:tab20)[j] : :white, legend=false, markersize=5)\n",
    "    end\n",
    "    plot!(p, sample_i[:, 1], sample_i[:, 2], color=:black, legend=false, ls=:dash)\n",
    "    scatter!(p, \n",
    "        [sample_i[argmax(sample_i[:, 2]), :][1]], \n",
    "        [sample_i[argmax(sample_i[:, 2]), :][2]], color=:black, legend=false\n",
    "    )\n",
    "    return p\n",
    "end\n",
    "\n",
    "plot(sample_plot(25), sample_plot(50), sample_plot(66), sample_plot(91), layout=(2,2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function normalise!(d)\n",
    "    z(s, μ, σ, ϵ) = (s - μ) / (σ + ϵ)\n",
    "    for i=1:size(d)[2]\n",
    "        tmp = d[:, i]\n",
    "        d[:, i] = z.(tmp, mean(tmp), std(tmp), 10e-10)\n",
    "    end\n",
    "    return d\n",
    "end\n",
    "\n",
    "for i=1:size(data_tensor)[2]\n",
    "    data_tensor[:, i, :] = normalise!(data_tensor[:, i, :])\n",
    "end\n",
    "\n",
    "data = map(s -> \n",
    "    map(i -> \n",
    "        s[findall(x -> x == i, clusters), :], 1:6)\n",
    "    , eachslice(data_tensor; dims=1)\n",
    ")\n",
    "\n",
    "labels = deepcopy(Matrix(dataset_a[:parameters]))\n",
    "normalise!(labels)\n",
    "labels = Vector{Float32}[eachrow(Matrix(labels))...]\n",
    "\n",
    "shuffle_vec = shuffle(1:length(data))\n",
    "\n",
    "function minibatch()\n",
    "    #idx = sample(1:length(data[1:80]), 1000, replace=true)\n",
    "    #data[1:80][idx], labels[1:80][idx]\n",
    "    data[shuffle_vec[1:80]], labels[shuffle_vec[1:80]]\n",
    "end\n",
    "\n",
    "function testbatch()\n",
    "    data[shuffle_vec[80:end]], labels[shuffle_vec[80:end]]\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Ecosystem from the XGML file and input ids mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eco = create_ecosystem(\"network.xgml\");\n",
    "eco.ii = Dict(1:6 .=> 1:6);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define models of components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_objects = []\n",
    "\n",
    "function get_model_dense(in::Int64, out::Int64)\n",
    "    d = Dense(in, out)\n",
    "    function get_model_dense(x)\n",
    "        reduce(vcat, d(x))\n",
    "    end\n",
    "    append!(params_objects, [d])\n",
    "    return get_model_dense\n",
    "end\n",
    "\n",
    "for i=1:6\n",
    "    eco.comps[string(\"h\",i)].model = get_model_dense(length(filter(x->x==i, clusters)), 40)\n",
    "end\n",
    "\n",
    "for i=1:6\n",
    "    eco.comps[string(\"hm\",i)].model = get_model_dense(80, 40)\n",
    "end\n",
    "\n",
    "function get_model_output(in::Int64, out::Int64)\n",
    "    d1 = Dense(in, 8)\n",
    "    d2 = Dense(8, out)\n",
    "    function get_model_output(x)\n",
    "        d2(d1(vcat(x...)))\n",
    "    end\n",
    "    append!(params_objects, [d1, d2])\n",
    "    return get_model_output\n",
    "end\n",
    "\n",
    "eco.comps[\"out1\"].model = get_model_output(6*40, 4)\n",
    "\n",
    "eco.schc = scv(eco.comps, eco.sch)\n",
    "eco.ps_obj = params_objects\n",
    "\n",
    "function nn(input_data::Any)\n",
    "    reduce(vcat, Maen.model(eco, input_data)[end])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minibatchrun = s -> map(x -> nn(x), s)\n",
    "loss = (x, y) -> mean(Flux.mse.(minibatchrun(x), y))\n",
    "\n",
    "dev = (x, y) -> mean(\n",
    "    abs.(reduce(hcat, minibatchrun(x)) .- reduce(hcat, y))./abs.(reduce(hcat, y)),\n",
    "    dims=1\n",
    ")\n",
    "acc = (x, y) -> mean(dev(x, y) .<= 0.2)\n",
    "\n",
    "Flux.Optimise.train!(\n",
    "    loss, Flux.params(eco.ps_obj), \n",
    "    repeatedly(minibatch, 1000), ADAM()\n",
    ")\n",
    "\n",
    "println(\"total train: accuracy = \", acc(minibatch()...), \" loss = \", loss(minibatch()...));\n",
    "println(\"total test: accuracy = \", acc(testbatch()...), \" loss = \", loss(testbatch()...));\n",
    "\n",
    "sum(length, Flux.params(eco.ps_obj))\n"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": "565c731531f64ed18ff15e0e0bb7dcee",
   "lastKernelId": "41e70bbf-488b-4d2b-a2a9-67bac752086c"
  },
  "kernelspec": {
   "display_name": "Julia 1.7.0",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "60aa0a847b2a6c4771b6f0a4a09c35a6025b095fa5d9ee644f9ad21b1db0180c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
